# Specify base URL starting with http or https, and end with a slash (/)
BaseUrl=http://www.seleniumframework.com/

# Configure any URLs you want to skip visiting during the crawling process - use RegEx patterns as appropriate
DontVisitSpecifiedUrls=False
DontVisitUrlsPattern=.*contenthandler.*

# Configure any image extensions you want to skip visiting during the crawling process - use RegEx patterns as appropriate
ImageExtensionsPattern=.*\\.(bmp|gif|jpg|png).*

# Configure any URLs which are used to represent error pages within the site being tested - use RegEx patterns as appropriate
# Any redirects to these URLs will be marked as a failure
FlagSpecifiedErrorPages=False
ErrorPageUrlsPattern=.*pagenotfound.htm.*|.*404error.*

# Configure the absolute path of the folder to be used to store temporary data during the crawl process
CrawlStorageFolder=D:\\Broken Link Tester

# Configure the delay (in milliseconds) between consecutive hits on the website being crawled
CrawlPolitenessDelay=200

# Configure the maximum number of pages to be crawled within the base URL specified; specify -1 for unlimited pages
CrawlMaxPagesToFetch=-1

# Configure a comma separated list of child pages within the base URL, which would act as seed URLs while crawling
CrawlSeeds=decision-models,python-basic,practice-videos,introduction

# Configure the number of parallel threads to be used while crawling
CrawlThreads=100

# Configure the network proxy settings
ProxyRequired=False
ProxyHost=48.19.199.100
ProxyPort=8080

# Configure the absolute path to be used for storing the test reports
ReportPath=D:\\Broken Link Tester

# Configure Email Notification Settings
SendEmailNotification=False
SmtpHost=smtp.gmail.com
SmtpPort=465
EmailSslEnable=True
EmailAuthRequired=False
EmailAuthUsername=vijay.ramaswamy@mycompany.com
EmailAuthPassword=mypassword
EmailFrom=vijay.ramaswamy@mycompany.com
EmailTo=stakeholders@mycompany.com
EmailSubject=Broken link test report
EmailBody=Please find attached the broken test report for today: